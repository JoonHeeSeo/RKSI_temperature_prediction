import pandas as pd
import torch
import torch.nn as nn
import torch.optim as optim
from sklearn.preprocessing import StandardScaler

# ================================
# 1. ë°ì´í„° ë¶ˆëŸ¬ì˜¤ê¸° ë° ì „ì²˜ë¦¬
# ================================
df = pd.read_csv("data/rksi_weather_2023.csv", parse_dates=["time"])

# ì‚¬ìš©í•  ë³€ìˆ˜ë“¤ë§Œ ì„ íƒ
features = ["tmin", "tmax", "prcp", "wspd", "pres"]
target = "tavg"

# ê²°ì¸¡ì¹˜ ìˆëŠ” í–‰ ì œê±°
df = df[features + [target]].dropna()

# X, y ì„¤ì •
X = df[features].values
y = df[target].values.reshape(-1, 1)

# ================================
# 2. ì •ê·œí™” (í‰ê·  0, í‘œì¤€í¸ì°¨ 1)
# ================================
scaler_X = StandardScaler()
scaler_y = StandardScaler()

X = scaler_X.fit_transform(X)
y = scaler_y.fit_transform(y)

# Torch í…ì„œ ë³€í™˜
X = torch.tensor(X, dtype=torch.float32)
y = torch.tensor(y, dtype=torch.float32)

# ================================
# 3. ë¹„ì„ í˜• íšŒê·€ ëª¨ë¸ (MLP) ì •ì˜
# ================================
model = nn.Sequential(
    nn.Linear(X.shape[1], 32),
    nn.ReLU(),
    nn.Linear(32, 16),
    nn.ReLU(),
    nn.Linear(16, 1)
)

criterion = nn.MSELoss()
optimizer = optim.Adam(model.parameters(), lr=0.01)

# ================================
# 4. í•™ìŠµ ë£¨í”„
# ================================
epochs = 200
for epoch in range(epochs):
    y_pred = model(X)
    loss = criterion(y_pred, y)

    optimizer.zero_grad()
    loss.backward()
    optimizer.step()

    if (epoch + 1) % 20 == 0:
        print(f"Epoch {epoch+1}/{epochs}, Loss: {loss.item():.4f}")

# ================================
# 5. ê²°ê³¼ ì¶œë ¥
# ================================
print("\nğŸ“ˆ í•™ìŠµëœ íŒŒë¼ë¯¸í„°:")
for name, param in model.named_parameters():
    print(f"{name}: {param.data.numpy().flatten()}")
